# Modeling Strategy

Gradient boosting models were selected due to their ability to handle:
- Nonlinear relationships
- Feature interactions
- Time-derived features

LightGBM was used as a benchmark model due to its speed and efficiency.

XGBoost was selected as the final model due to:
- Lower RMSE and MAE
- Better generalization
- More stable predictions on unseen data

Only one model is used in the final simulation to match industry standards.

